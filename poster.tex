\documentclass{article}
\input{style.sty}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\pgfplotsset{
  xticklabel={$\mathsf{\pgfmathprintnumber{\tick}}$},
  yticklabel={$\mathsf{\pgfmathprintnumber{\tick}}$},
}
\usetikzlibrary{intersections}
\usepackage{lipsum}  

\usepackage[
  paperwidth=90cm,
  paperheight=120cm,
  top=25cm,
  left=9cm,
  right=9cm,
]{geometry}


\usepackage{wallpaper}
\CenterWallPaper{1}{assets/background}

\usepackage{fontspec}
\setmainfont{Arial}

\usepackage[BoldFont, SlantFont]{xeCJK}
\setCJKmainfont{Microsoft JhengHei}

\usepackage[absolute]{textpos}
\TPGrid[80mm,390mm]{15}{12}

\parindent=0pt
\parskip=\baselineskip

\begin{document}
% disable page numbering
\thispagestyle{empty}
\membersize \textbf{第17組：朱劭璿、陳居廷}\hspace{20.5cm}\textbf{指導老師：陳嘉平 教授}
\bigskip

\titlesize \textbf{TSM-Net: 以對抗式時序壓縮自編碼器為基礎的音訊變速演算法 \\
TSM-Net: Temporal Compressing Autoencoder with Adversarial Losses for Time-Scale Modification on Audio Signals}

\begin{textblock}{7.0}(0,0)
\Head{Introduction} \\
\Large
With the advance of technologies and digitalization, we can store and reproduce multimedia content nowadays. An ubiquitous application regarding audio signals called time-scaled modification (TSM) is used in our daily life. It's also known as playback speed control in the video streaming platforms such as YouTube. With the power of artificial intelligence (AI) and modern computation hardware, however, we haven't discovered any method using AI to refine TSM algorithm and leverage the quality of the synthetic audio to the next level.

We proposed a novel TSM approach. While traditional methods use framing technique and spectral approaches use short-time Fourier transform to get high-level units. TSM-Net, our neural-network model encodes the raw audio into a high-level latent representation called Neuralgram. Since the resulting Neuralgram is a two-dimensional image with real values, we apply some existing image resizing techniques on the Neuralgram and decode it using our neural decoder to obtain the time-scaled audio. \\

\medskip
\Head{Related Works} \\
\Large
 Modeling audio is not a trivial task for neural networks. Models that directly generate raw audio waveform are known as vocoder.

\input{assets/alias-illus.tex}

\medskip
\Head{Methodology} \\
\Large \lipsum[3-3]
\end{textblock}

\begin{textblock}{7.0}(8,0)
\Head{Experiment} \\
\Large \lipsum[4-4]
\large \input{assets/tsm-illus.tex}

\medskip
\Head{Conclusion} \\
\Large \lipsum[5-5]
\end{textblock}


\end{document}
